# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NdF_oZbOW-RL2wA2o5Vxfa_uJ7Ns_YvO

# Step 1: Environment Setup and Data Loading
1. Set Up Google Colab Environment: If you haven't already, ensure your Google Colab environment is ready for use.

2. Import Necessary Libraries:
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import gridspec
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import f1_score, matthews_corrcoef
from sklearn.metrics import confusion_matrix
from sklearn.impute import SimpleImputer

"""Load the Dataset: Assuming you've mounted your in file of Collab and have the dataset path"""

data = pd.read_csv("/content/sample_data/creditcard.csv")

"""# Step 2: Data Preprocessing
1. Understanding and Describing the Data:
"""

print(data.head())
print(data.shape)
print(data.describe())

"""2.Handling Imbalanced Data:

-Calculate the imbalance ratio.

"""

fraud = data[data['Class'] == 1]
valid = data[data['Class'] == 0]
print(f'Fraud Cases: {len(fraud)}')
print(f'Valid Transactions: {len(valid)}')

"""3.Data Cleaning:

Check for and handle missing values. For simplicity, we'll fill NaNs with the median value.

"""

imputer = SimpleImputer(strategy='median')
data_filled = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)

"""4.Feature Selection and Data Split:

Separate features (X) and target (Y), and split the dataset.
"""

imputer = SimpleImputer(strategy='median')
data_filled = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)

X = data_filled.drop(['Class'], axis=1)
Y = data_filled['Class']
xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size=0.2, random_state=42)

"""# Step 3: Model Building and Training
 1. Random Forest Model:

"""

rfc = RandomForestClassifier()
rfc.fit(xTrain, yTrain)

"""# Step 4: Model Evaluation
  1. Predictions and Evaluating Metrics:


"""

yPred = rfc.predict(xTest)
print(f"Accuracy: {accuracy_score(yTest, yPred)}")
print(f"Precision: {precision_score(yTest, yPred)}")
print(f"Recall: {recall_score(yTest, yPred)}")
print(f"F1-Score: {f1_score(yTest, yPred)}")
print(f"Matthews Correlation Coefficient: {matthews_corrcoef(yTest, yPred)}")

"""  2.Confusion Matrix Visualization:"""

conf_matrix = confusion_matrix(yTest, yPred)
sns.heatmap(conf_matrix, annot=True, fmt="d", xticklabels=['Normal', 'Fraud'], yticklabels=['Normal', 'Fraud'])
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# Correlation matrix
corrmat = data.corr()
fig = plt.figure(figsize = (12, 9))
sns.heatmap(corrmat, vmax = .8, square = True)
plt.show()

"""# Step 5: Reanalyze and Refine
Reanalyze: Review the model's performance metrics. If the performance is not satisfactory, consider hyperparameter tuning, trying different models, or further preprocessing the data.

Training Strategy: Depending on the model's performance, consider strategies like oversampling the minority class, undersampling the majority class, or employing more sophisticated techniques like SMOTE for balancing the dataset.

Model Comparison: If necessary, compare the Random Forest model with other algorithms like Gradient Boosting, Logistic Regression, or Neural Networks to find the best performing model for your specific dataset.
"""

from imblearn.over_sampling import SMOTE
# Initialize SMOTE
smote = SMOTE(random_state=42, k_neighbors=min([5, len(yTrain[yTrain == 1]) - 1]))

# Balance the dataset
xTrain_balanced, yTrain_balanced = smote.fit_resample(xTrain, yTrain)
# Training RandomForest on the balanced dataset
rfc.fit(xTrain_balanced, yTrain_balanced)

# Predictions
yPred_balanced = rfc.predict(xTest)

# Check the number of samples in the minority class
minority_class_count = len(yTrain[yTrain == 1])
print(f"Minority class sample count: {minority_class_count}")

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression

# Initialize models
gb = GradientBoostingClassifier()
lr = LogisticRegression(max_iter=1000)

# Train models
gb.fit(xTrain_balanced, yTrain_balanced)
lr.fit(xTrain_balanced, yTrain_balanced)

# Predictions
yPred_gb = gb.predict(xTest)
yPred_lr = lr.predict(xTest)

# Evaluation
def evaluate_model(y_test, y_pred):
    print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
    print(f"Precision: {precision_score(y_test, y_pred)}")
    print(f"Recall: {recall_score(y_test, y_pred)}")
    print(f"F1-Score: {f1_score(y_test, y_pred)}")

print("RandomForest:")
evaluate_model(yTest, yPred_balanced)

print("\nGradientBoosting:")
evaluate_model(yTest, yPred_gb)

print("\nLogisticRegression:")
evaluate_model(yTest, yPred_lr)

"""Hyperparameter Tuning: The param_grid in the GridSearchCV example is just a starting point. Depending on computational resources and time, you might want to expand or narrow down the search.

SMOTE: While SMOTE can help balance the dataset, it's essential to only apply it to the training data to avoid information leakage into the test set.

Model Evaluation: The evaluation function evaluate_model gives a quick comparison across different metrics. Depending on your specific requirements (e.g., reducing false positives), you might prioritize some metrics over others.

Final Model Choice: The choice of the best model can depend on the specific performance metric you're optimizing for (e.g., recall, precision, F1-score). It's also essential to consider the model's interpretability and the computational cost of training and inference.
"""